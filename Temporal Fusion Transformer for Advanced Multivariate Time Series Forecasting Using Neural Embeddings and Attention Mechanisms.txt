import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader

# -----------------------------------------------------
# 1) SYNTHETIC MULTIVARIATE TIME SERIES DATA GENERATION
# -----------------------------------------------------
def generate_dataset(n_samples=2000, seq_len=30):
    static_cat = np.random.randint(0, 5, size=n_samples)
    static_num = np.random.randn(n_samples)

    tv1 = np.sin(np.linspace(0, 20, n_samples)) + np.random.randn(n_samples) * 0.1
    tv2 = np.cos(np.linspace(0, 20, n_samples)) + np.random.randn(n_samples) * 0.1
    tv3 = np.random.randn(n_samples)

    target = (
        0.4 * tv1
        - 0.2 * tv2
        + 0.1 * tv3
        + static_cat * 0.05
        + static_num * 0.03
        + np.random.randn(n_samples) * 0.1
    )

    df = pd.DataFrame({
        "static_cat": static_cat,
        "static_num": static_num,
        "tv1": tv1,
        "tv2": tv2,
        "tv3": tv3,
        "target": target,
    })

    sequences = []
    for i in range(len(df) - seq_len):
        sequences.append(df.iloc[i:i+seq_len])

    return sequences


# -------------------------------
# Data Loader for TFT-like model
# -------------------------------
class TimeSeriesDataset(Dataset):
    def __init__(self, sequences):
        self.data = sequences
        self.seq_len = len(sequences[0])

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        df = self.data[idx]
        static_cat = torch.tensor(df["static_cat"].iloc[0], dtype=torch.long)
        static_num = torch.tensor(df["static_num"].iloc[0], dtype=torch.float32)

        tv = torch.tensor(df[["tv1", "tv2", "tv3"]].values, dtype=torch.float32)
        y = torch.tensor(df["target"].values[-1], dtype=torch.float32)
        return static_cat, static_num, tv, y


# -------------------------------------
# 2) TEMPORAL FUSION TRANSFORMER MODEL
# -------------------------------------
class TFT(nn.Module):
    def __init__(self, cat_sizes=5, embed_dim=8, hidden_dim=32, n_heads=4):
        super().__init__()

        self.static_cat_embed = nn.Embedding(cat_sizes, embed_dim)
        self.static_num_fc = nn.Linear(1, embed_dim)

        self.encoder = nn.TransformerEncoder(
            nn.TransformerEncoderLayer(
                d_model=embed_dim + 3, 
                nhead=n_heads, 
                batch_first=True
            ),
            num_layers=2,
        )

        self.attention_fc = nn.Linear(embed_dim + 3, 1)
        self.fc_out = nn.Linear(embed_dim + 3, 1)

    def forward(self, static_cat, static_num, tv):
        cat_emb = self.static_cat_embed(static_cat)
        num_emb = self.static_num_fc(static_num.unsqueeze(-1))
        static_context = cat_emb + num_emb

        static_rep = static_context.unsqueeze(1).repeat(1, tv.shape[1], 1)
        x = torch.cat([tv, static_rep], dim=2)

        x_trans = self.encoder(x)

        attn_weights = torch.softmax(self.attention_fc(x_trans).squeeze(-1), dim=1)
        context = (x_trans * attn_weights.unsqueeze(-1)).sum(dim=1)

        out = self.fc_out(context)
        return out.squeeze(), attn_weights


# -----------------------
# TRAINING + EVALUATION
# -----------------------
def train_model():
    seq = generate_dataset()
    split = int(len(seq) * 0.8)
    train_seq, test_seq = seq[:split], seq[split:]

    train_loader = DataLoader(TimeSeriesDataset(train_seq), batch_size=32, shuffle=True)
    test_loader = DataLoader(TimeSeriesDataset(test_seq), batch_size=32, shuffle=False)

    model = TFT()
    optim = torch.optim.Adam(model.parameters(), lr=1e-3)
    loss_fn = nn.MSELoss()

    # -----------------------
    # Training Loop
    # -----------------------
    for epoch in range(10):
        model.train()
        losses = []
        for sc, sn, tv, y in train_loader:
            optim.zero_grad()
            pred, _ = model(sc, sn, tv)
            loss = loss_fn(pred, y)
            loss.backward()
            optim.step()
            losses.append(loss.item())
        print(f"Epoch {epoch+1}, Loss = {np.mean(losses):.4f}")

    # -----------------------
    # Testing Performance
    # -----------------------
    model.eval()
    preds, trues = [], []
    attn_list = []

    with torch.no_grad():
        for sc, sn, tv, y in test_loader:
            pred, attn = model(sc, sn, tv)
            preds.extend(pred.numpy())
            trues.extend(y.numpy())
            attn_list.append(attn)

    preds = np.array(preds)
    trues = np.array(trues)
    rmse = np.sqrt(np.mean((preds - trues) ** 2))
    mae = np.mean(np.abs(preds - trues))

    print("RMSE:", rmse)
    print("MAE:", mae)

    return model, rmse, mae, attn_list


if __name__ == "__main__":
    model, rmse, mae, attn = train_model()